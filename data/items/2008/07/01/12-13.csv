ID,Type,Story,Parent,Points,Comments,Author,Title,URL,Content,Created
232889,story,,,5,1,edw519,"How to See 93 Million Miles: Plan a Trip to a Total Solar Eclipse",http://www.wired.com/science/space/news/2008/06/solar_eclipse?currentPage=all,,1214917127
232888,story,,,1,0,gibsonf1,"Cnet buy puts CBS in top 10 Web properties",http://www.sfgate.com/cgi-bin/article.cgi?f=/c/a/2008/07/01/BUJF11HHLF.DTL,,1214917066
232887,comment,232533,232646,0,0,akv,,,"I ran some experiments with this. The results are here:<p><a href=""http://news.ycombinator.com/item?id=232882"" rel=""nofollow"">http://news.ycombinator.com/item?id=232882</a>",1214917027
232886,comment,232866,232866,0,0,dhotson,,,"I wonder if this could be combined with this javascript jabber library to make a fully fledged chat client:\n<a href=""http://zeank.in-berlin.de/jsjac/"" rel=""nofollow"">http://zeank.in-berlin.de/jsjac/</a><p>.. currently that library is restricted by the same domain policy. I wonder how this Comet library manages to get around it.<p>Anyone here care to explain?",1214917016
232885,story,,,12,18,fromedome,"Hulu a consumer success but still a small business: Est. $12.5-25mm net revs",http://www.alleyinsider.com/2008/7/hulu-a-consumer-success-but-still-a-small-business,,1214917011
232884,comment,232695,232748,0,0,jm4,,,"It seems that way. As someone who develops a crawler that currently parses Flash files to find child files and links to external content I was excited when I first read that Adobe had made a special version of the Flash player that could be used by bots. I'm sure theirs has many more features than mine. That quickly turned to disappointment when I found out this is only for Google and Yahoo. This is totally anti-competetive. I wonder how Microsoft will react. In any case, unless they are willing to make this available for everyone my opinion of Flash and Adobe is pretty much the same as it was yesterday.<p>[edit]\nIt's probably worth noting that I'm making the big assumption that this isn't something that was solicited by Google and Yahoo. Afterall, Flash has never been indexed before and it never seemed to bother them. It seems to be much more a problem for Adobe since the major search engines are pretty much in a position where they can tell content providers to F- off if they've developed their whole site in something like Flash. It's possible Google and Yahoo chose to pay for this or work out some kind of agreement and in that case there's nothing to gripe about.",1214916965
232883,story,,,4,0,Allocator2008,"Planets orphaned from solar systems may retain heat",http://www.world-science.net/exclusives/070910_sunless-planets.htm,,1214916832
232882,story,,,8,1,akv,"Hacker News network of users (based on commenting behavior)",,"There has been a lot of discussion lately on trust measures, reputation and groups on Hacker News. So, I decided to run some experiments on the crawled dataset of stories released by Xirium (http://news.ycombinator.com/item?id=182374).<p>Of course, the real database of voting history of users would have been much better, but this is all I could get...<p>Calculation<p>The trust values were calculated as follows:\n1. For each story the submitter gets +1 from all commentors. I know this is naive, but bec. of lack of voting history (on the story), I had to go with this assumption.\n2. Each commentor gets ( votes_on_that_comment / total_votes_on_all_comment ) for each comment on that story, from all other commentors. (Again I know this is naive).\n3. Trust values are added up for (object, subject) pairs across all stories.\n4. The votes on the story were recorded as votes from a virtual user 'HNCROWD' for the submitter. After adding up, the trust value from HNCROWD for a user reflects the 'Karma' of the user on the website.<p>The resulting file is downloadable in CSV format here: http://www.sendspace.com/file/mw59f7<p>So with these values I tried running some experiments:<p>1. Clustering:\nAn interesting experiment would be see if there are clusters of users among commentors. I used the Markov Clustering Algorithm (http://micans.org/mcl/) for clustering graphs as it does not need the number of clusters as initial input.<p>Unsurprisingly enough, most of the Hacker News community belongs to a single cluster. This makes sense as Hacker News is quite a focussed community interested in practical hacking related to the web, entrepreneurship and startups.<p>Other explainations are that users who comment are themselves quite interested in the stories and the community and are hence closely connected and similar. The users who are dissappointed with the website, might not be commenting at all... Again, using voting statistics would have been better.<p>2. Trust-Rank:\nSecond, I tried applying a variation of the TrustRank algorithm ( http://www.vldb.org/conf/2004/RS15P3.PDF ) to the trust values data.<p>The result here was also unsurprising. The ordering of users was very similar to what is generated using Karma on Hacker News website.<p>Further work:\n1. The method of calculating trust values (based on comments) is very basic and needs to improved (like taking into account threads and opposing opinions).\n2. I want to see if this information is actually useful in tasks like News Recommendation.<p>Conclusions:<p>Without the availability of voting data, it is hard to say if users on a focussed site like Hacker News have diverging interests. I am sure, as the community grows people of different interests are bound to join. But, the whole idea of a democratic voting site only allows stories that are interesting to the most active users to be selected. And so, other users will find the website boring, and not contribute and maybe leave. This might be an example of a community maintaining itself...<p>Giving highly trusted users down-modding power will strengthen this emergent behaviour, and the community will become more focussed (towards these users) than it is now. This might be both good and bad depending on if you are in this majority...<p>Comments are welcome... Leave your feedback here: http://arnavk.blogspot.com/2008/07/hacker-news-network-of-users-based-on.html<p>P.S. Thanks to Xirium for sharing the dataset.",1214916801
232881,story,,,5,28,yearsinrock,"After c/c++ what should I learn?",,"I had c and c++ in my 2nd year's CS semester.\nwhat programming languages should i learn after these.should i strengthen my skills in these languages again or should i try learning other prog languages?which ones are useful for web development?\nWhat if i wanted to develop a small website all by my own ,then which languages do i require to learn?",1214916732
232880,comment,232866,232866,0,0,nirmal,,,"So this is just a better framework on top of HTTP Bind? It's not true sockets because I still can't open up many simultaneous connections. The max-persistent-connections-per-server was what always annoyed me when it came to using this type of architecture.<p>Has anyone seen code that manages to multiplex a single connection of this type across multiple tabs within a browser? Is that even possible?<p>From: <a href=""http://www.orbited.org/wiki/CherryChat"" rel=""nofollow"">http://www.orbited.org/wiki/CherryChat</a><p><i>""Then point your browser at <a href=""http://localhost:4700/static/chat.html"" rel=""nofollow"">http://localhost:4700/static/chat.html</a>, and then open a second browser window and point it at <a href=""http://127.0.0.1:4700/static/chat.html"" rel=""nofollow"">http://127.0.0.1:4700/static/chat.html</a>, and test the application. It’s important to use the two different hostnames localhost and 127.0.0.1 because some browsers limit the number of open connections you can have to each hostname to two. With this limit it is impossible to run two instances of the chat application on the same host. Of course, 127.0.0.1 and localhost should refer to the same local machine, so its a good way of tricking the browser into thinking its talking to separate servers.""</i>",1214916361
232879,story,,,3,0,fromedome,"Will Apple sweeten the iPhone deal at the last minute again?",http://www.alleyinsider.com/2008/7/will-apple-sweeten-the-iphone-deal-at-the-last-minute-again,,1214916258
232878,comment,232351,232814,0,0,subwindow,,,"Probably a little bit, but they're just one site.  Google would never put so much influence on one site- it is too gameable.",1214915958
232877,comment,232861,232861,0,0,brk,,,"A) I'd recommend that you reallocate your shares sooner rather than later so that you actually have a pool of unallocated stock to distribute to other new employees.<p>B) I think that you have to sit together as a team of 3 and determine what you think this persons value contribution will be.  You are on the right track with a base+bonus thought.  Remember also that you can arrange for the shares to vest over a period of time.  This helps minimize the threat that you give someone more shares than they are worth - as the shares vest you gain better insight into the persons value contribution.",1214915943
232876,story,,,2,0,fromedome,"Google subletting office space in NYC",http://www.alleyinsider.com/2008/7/google-subletting-office-space-at-chelsea-market,,1214915873
232875,story,,,1,0,sanj,"Development Phase Code Signing ",http://www.red-sweater.com/blog/514/development-phase-code-signing,,1214915686
232874,story,,,2,0,sanj,"Working With History in Bash",http://blog.macromates.com/2008/working-with-history-in-bash/,,1214915663
232873,story,,,1,0,robg,"An enlightening study of nerd history - Review of American Nerd: The Story of My People",http://www.boston.com/ae/books/articles/2008/06/25/an_enlightening_study_of_nerd_history/,,1214915403
232872,story,,,1,1,techcore,"Nielsen: Digg Traffic Sucks. Mashable: That’s What She Said",http://mashable.com/2008/07/01/nielsen-digg-traffic/,"Discuss: the true value of social media traffic.",1214915222
232871,comment,231236,231416,0,0,utx00,,,"ah. sure. timr wins this one ;)",1214915145
232870,story,,,3,0,mhb,"Hookworms relieve allergy symptoms - researcher tests by infecting himself",http://www.nytimes.com/2008/07/01/health/research/01prof.html,,1214914837
232869,comment,232623,232623,0,0,noonespecial,,,"XP is a specialized tool for getting specialized results. As the article mentioned, it is good for getting large volumes of average code. (And likely doing so with fewer mistakes).<p>We XP for the same reason we have 2 pilots on an airliner. Its long and boring but messing up can be very bad. So we send 2 people to manage the drudgery, keep each other motivated and catch mistakes that could lead to problems later.<p>The virtue of the lone expert however, applies to a very different type of problem. He has to be free to try the most wild outlandish things that pop into his head. This is not possible in a ""pair programming"" environment. There is astonishingly little difference between design flaw and brilliant innovation in this space.<p>When we test the X-1 we send Chuck Yeager not a pair of pilots from Delta.",1214914832
232868,comment,232533,232533,0,0,sanj,,,"Wow, I had a completely different idea based on the title:<p>Incorporating rankings from news-voting sites (digg, yc, reddit) directly into pagerank for search.",1214914825
232867,comment,232533,232674,0,0,Malcx,,,">>It would discourage new users, as they would likely never catch up to early adopters.<p>Adding a time based decay to the rank could address that. I.e. my vote for you 1 month ago is worth less then the vote 1 min ago...",1214914355
