ID,Type,Story,Parent,Points,Comments,Author,Title,URL,Content,Created
96114,comment,96057,96057,0,0,toddcw,,,"You ought to check out screen-scraper (<a href=""http://www.screen-scraper.com/"" rel=""nofollow"">http://www.screen-scraper.com/</a>).  It's a commercial app, but the best I've used for this kind of thing.  They also offer a freeware version.",1199825944
96113,story,,,2,1,jrr2015,"fast search",http://www.techcrunch.com/2008/01/08/microsoft-has-announced-a-takeover-bid-for-fast-search-transfer-priced-at-12-billion/,,1199825932
96112,story,,,3,0,pius,"Evolutionary Theology: How to Love God and Science | Wired Science from Wired.com",http://blog.wired.com/wiredscience/2007/12/evolutionary-th.html#previouspost,,1199825740
96111,comment,95903,95991,0,0,akkartik,,,"Nice quote. According to Google it's on the net in only one other place:
  <a href=""http://theaegispress.com/Philosophy%20of%20Goethe.pdf"" rel=""nofollow"">http://theaegispress.com/Philosophy%20of%20Goethe.pdf</a><p>Which turns out to be a pretty good article. The phrase after this quote is pretty interesting too as a summary of what is desirable:<p>""Always striving and always working toward a new synthesis..""<p>Read the whole thing.",1199825506
96109,comment,96020,96048,0,0,pius,,,"That's precisely what I was thinking.  Until I see an actual implementation, I'm assuming this is just a token gesture.",1199825283
96107,comment,96079,96079,0,0,zoltz,,,"I agree that this is the potentially ""hottest"" statement from the story. Yet only two examples are given: Google and Twitter. Taking away the clutter around the search box was a good idea, but wasn't Google's real innovation something like counting links to pages to judge their significance? The Twitter example is better, but one example is not enough to make the case. Are there others?",1199825222
96106,comment,96057,96057,0,0,akkartik,,,"Another talk I saw at shdh in october (<a href=""http://superhappydevhouse.org/SuperHappyDevHouse20"" rel=""nofollow"">http://superhappydevhouse.org/SuperHappyDevHouse20</a>):<p><a href=""http://tagtheplanet.net"" rel=""nofollow"">http://tagtheplanet.net</a><p>They seem to be attempting an intelligent crawler as well.",1199825032
96105,story,,,3,2,pius,"Tutorial on embedding concurrent Erlang into Ruby",http://www.chuckvose.com/articles/2008/01/07/concurrent-code-in-ruby-1-8-6-through-inlining,,1199825031
96104,story,,,1,0,ivan,"Microsoft Bids for Norwegian Search Engine Firm ",http://www.nytimes.com/2008/01/08/technology/08cnd-soft.html?_r=1&ref=technology&oref=slogin,,1199824993
96103,story,,,1,0,hhm,"VideoTrace: Very Impressive Project for 3d Modeling from Video",http://www.acvt.com.au/research/videotrace/,,1199824743
96102,comment,96057,96057,0,0,akkartik,,,"For 1 you mean you want to build a <i>parser</i> for arbitrary html that your crawler returns. Hard problem, as others have said. My advice:<p>1. Use an html parsing library. Beautiful soup (python) or hpricot (ruby) are good building blocks.<p>2. Practice manually building parsers for a few sites, then see if it leads you to any insights about how to generalize the process.<p>3. Ignore everything else until you do 2. Just use wget as your crawler. Skip the visual interface for now; just parsing arbitrary pages is a hard enough problem to bite off.",1199824234
96101,comment,96057,96057,0,0,spoonyg,,,"I have built up something similar to what you are describing and it was a fun project. My first reaction to #1 is that if the information you want to repeatably in the same place you are probably better off just doing things manually and not going to the trouble of building a visual tool.
In my experience the interesting pieces of data tend to move around and something like regex is the best way to handle this.
I used wget to grab data because it was quick and easy. I then did the post processing in the background, separating out the grabbing of data and the interpretation of data.",1199824229
96100,comment,96080,96080,0,0,mrtron,,,"Way back during frosh week in university, I went on stage during a hypnosis guy just for fun.<p>I tried to get into it as hard as I could and go with the flow, it wasn't happening.  My friends on stage who did get 'hypnotized' said they were just doing whatever he said to act foolish and have fun.<p>Either way, it turns into an entertaining stage act having some people running around doing whatever you say.  Convincing frosh to do stupid things is as easy as depressing teenagers.",1199824172
96099,comment,96057,96057,0,0,showerst,,,"I know in php it's possible to load an html document and parse the DOM tree using XPath expressions, presumably that capability exists in python.<p>So i guess in theory you could write a frontend (firefox extension?) where you could highlight / select a screen area (webdeveloper already does this), then pass it's DOM information (i.e. #body table tr td#username ) to your backend, which would then scrape that field(s) from any applicable site pages.<p>This of course assumes that 1) The website(s) are well formed enough for your parser and 2) Well programmed enough that the same info is in the same place in the DOM tree, and preferably ID'd, which are pretty HUGE assumptions, but could be worked around if you were determined enough.<p>Not sure if this is what you're looking for, and it seems a bit circuitous, but it's a plausible idea anyway.",1199824112
96098,comment,95857,96084,0,0,davidw,,,"Some fruit doesn't hang quite that low, though.",1199823926
96097,comment,96057,96057,0,0,akkartik,,,"I remember seeing a screencast of some startup that did something like this. It was maybe a year ago. You click on elements, it shows you other hypotheses, you correct if necessary, and you get an RSS feed compiled from the page structure.<p>Anybody remember this?",1199823698
96096,comment,96057,96057,0,0,aristus,,,"I think you are in over your head, but it's a great way to learn about the plumbing and underbelly of the Web.<p>This visual tool is basically what a company called onDisplay was doing back in 1999, before they were bought by consulting firm Vignette for an obscene amount of money. But scraping against the html structure is a losing battle.<p>A better approach is to use clues in the information itself to guess its content: something with a ""$"" is a price. Something containing ""toyota"" is probably a name, ""blue"" a color, more than 20 words containing ""good"", ""v8"" is a description, etc. That way your scraper is resistant to structure changes.<p>All that is separate from the problem of a crawler. It takes a long time and a lot of effort to convince content sites that what you are doing is a) helpful to them and b) something they should not be doing themselves.<p>It's like jumping on stage with the band and starting to play. You better be really good and friendly and prepared to get the crap beaten out of you.",1199823672
96095,comment,96057,96091,0,0,ivan,,,"Why thousands of job sites produce custom xml output for simplyhired or indeed ??",1199823640
96094,comment,96010,96010,0,0,Funky_,,,"My college switched from C++ to Java based coding in 2005 for learning the fundamentals. I would have much rather learned C++.",1199823608
96093,comment,96057,96057,0,0,bluelu,,,"What do you want to do?<p>At least in Germany, there exists a few solutions which do exactly that.
If a person puts his car on sale (a bargain) on one of the car related websites, he get's the first call in about 20 seconds from someone using these programs.",1199823580
96092,comment,96024,96073,0,0,gabeisbored,,,"Trans just sent me a link to this thread... is that guerrilla guerrilla guerrilla marketing?",1199823553
96091,comment,96057,96090,0,0,akkartik,,,"Because granting permission is easy. Why would they go to more effort than that for random people?",1199823473
96090,comment,96057,96057,0,0,ivan,,,"And still one thing .. if you want to ask the site owner for permissions, why not ask them to produce some specific xml file for you?",1199823385
96089,comment,96024,96024,0,0,gabeisbored,,,"Show me any example of ""guerrilla marketing"" that doesn't take advantage of some system. That's what makes it ""guerrilla"". This example is no less guerrilla than SPAM itself.",1199823338
96087,comment,95680,95867,0,0,neilk,,,"It's been pointed out to me that ""Fail"" is hardly constructive criticism. I'll try to update my blog post (linked below) with  something that might actually help.",1199823139
96085,comment,96024,96073,0,0,transburgh,,,"I see your point. True.",1199822905
96084,comment,95857,95926,0,0,pg,,,"You've answered your own question.  One of the (many) advantages of releasing quickly is that it's better for morale.",1199822766
96082,comment,95912,95999,0,0,eru,,,"""This page originally continued with an anti-Microsoft jeremiad. On reflection, however, I think I'd prefer to finish by thanking the principal authors, Vinod Valloppillil and Josh Cohen, for authoring such remarkable and effective testimonials to the excellence of Linux and open-source software in general. I suspect that historians may someday regard the Halloween memoranda as your finest hour, and the Internet community certainly owes you a vote of thanks.""",1199822575
96081,comment,96024,96024,0,0,damienkatz,,,"What's it doing is abusing a useful social system where lost articles are returned to owners. It's not guerilla marketing, it's spamming.",1199822505
96080,story,,,1,5,hhm,"The Truth and the Hype of Hypnosis",http://www.sciam.com/article.cfm?id=the-truth-and-the-hype-of,,1199822477
